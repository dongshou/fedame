"""
FedPCI è”é‚¦å­¦ä¹ æœåŠ¡ç«¯ (é‡æ„ç‰ˆ)

æ ¸å¿ƒç‰¹ç‚¹ï¼š
- ç®¡ç†å…¨å±€æ¨¡å‹
- èšåˆè§„åˆ™ï¼š
  - g_common: èšåˆ
  - g_ind: ä¸èšåˆï¼ˆå®¢æˆ·ç«¯æœ¬åœ°ä¿ç•™ï¼‰
  - classifier_common: èšåˆ
  - classifier_full: ä¸èšåˆ
  - prototypes: é€‰æ‹©æ€§èšåˆï¼ˆä»…æ‹¥æœ‰è¯¥ç±»çš„å®¢æˆ·ç«¯å‚ä¸ï¼‰
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple
import copy

from models.fedpci_model import FedPCIModel
from models.backbone import create_backbone


class FedPCIServer:
    """
    FedPCI è”é‚¦æœåŠ¡ç«¯ (é‡æ„ç‰ˆ)
    """
    
    def __init__(
        self,
        num_classes: int,
        class_names: List[str],
        model_config: Dict,
        device: str = "cuda",
        momentum: float = 0.5
    ):
        self.num_classes = num_classes
        self.class_names = class_names
        self.device = device
        self.momentum = momentum  # åŠ¨é‡ç³»æ•°
        
        # åˆå§‹åŒ–å…¨å±€æ¨¡å‹
        self._init_global_model(model_config)
        
        # å·²å­¦ä¹ çš„ç±»åˆ«
        self.learned_classes: List[int] = []
        
        # è®°å½•æ¯ä¸ªç±»æœ‰å¤šå°‘å®¢æˆ·ç«¯æ‹¥æœ‰
        self.class_client_count: Dict[int, int] = {c: 0 for c in range(num_classes)}
    
    def _init_global_model(self, config: Dict):
        """åˆå§‹åŒ–å…¨å±€æ¨¡å‹"""
        # Backboneï¼ˆå†»ç»“ï¼‰
        self.backbone = create_backbone(
            backbone_type=config.get('backbone', 'resnet18'),
            pretrained=config.get('backbone_pretrained', True),
            frozen=True
        ).to(self.device)
        
        # FedPCI æ¨¡å‹
        self.global_model = FedPCIModel(
            num_classes=self.num_classes,
            input_dim=config.get('feature_dim', 512),
            hidden_dim=config.get('hidden_dim', 256),
            output_dim=config.get('output_dim', 128),
            num_layers=config.get('num_layers', 3),
            dropout=config.get('dropout', 0.1)
        ).to(self.device)
    
    def get_global_params(self) -> Dict[str, any]:
        """
        è·å–å…¨å±€å‚æ•°ï¼ˆå‘é€ç»™å®¢æˆ·ç«¯ï¼‰
        
        Returns:
            dict containing:
                - g_common: å…±æ€§åˆ†æ”¯å‚æ•°
                - classifier_common: å…±æ€§åˆ†ç±»å¤´å‚æ•°
                - prototypes: åŸå‹å‚æ•°
        """
        return self.global_model.get_aggregatable_params()
    
    def prepare_task(self, task_classes: List[int]) -> Dict:
        """
        å‡†å¤‡æ–°ä»»åŠ¡
        
        Args:
            task_classes: ä»»åŠ¡åŒ…å«çš„ç±»åˆ«ID
        
        Returns:
            task_info: ä»»åŠ¡ä¿¡æ¯
        """
        new_classes = [c for c in task_classes if c not in self.learned_classes]
        
        return {
            'task_classes': task_classes,
            'new_classes': new_classes,
            'old_classes': self.learned_classes.copy()
        }
    
    def aggregate(
        self,
        client_updates: List[Dict[str, any]],
        verbose: bool = False
    ):
        """
        èšåˆå®¢æˆ·ç«¯æ›´æ–°
        
        èšåˆè§„åˆ™ï¼š
        - g_common: FedAvg + åŠ¨é‡
        - classifier_common: FedAvg + åŠ¨é‡
        - prototypes: é€‰æ‹©æ€§èšåˆï¼ˆä»…æ‹¥æœ‰è¯¥ç±»çš„å®¢æˆ·ç«¯å‚ä¸ï¼‰+ åŠ¨é‡
        
        Args:
            client_updates: å®¢æˆ·ç«¯æ›´æ–°åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
                - g_common: å…±æ€§åˆ†æ”¯å‚æ•°
                - classifier_common: å…±æ€§åˆ†ç±»å¤´å‚æ•°
                - prototypes: åŸå‹å‚æ•°
                - local_classes: æœ¬åœ°æ‹¥æœ‰çš„ç±»åˆ«
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
        """
        if len(client_updates) == 0:
            return
        
        num_clients = len(client_updates)
        
        # ============ 1. èšåˆ g_common ============
        old_g_common = self.global_model.get_common_branch_params()
        new_g_common = self._aggregate_params(
            [u['g_common'] for u in client_updates],
            old_g_common
        )
        self.global_model.set_common_branch_params(new_g_common)
        
        # ============ 2. èšåˆ classifier_common ============
        old_classifier = self.global_model.get_classifier_common_params()
        new_classifier = self._aggregate_params(
            [u['classifier_common'] for u in client_updates],
            old_classifier
        )
        self.global_model.set_classifier_common_params(new_classifier)
        
        # ============ 3. é€‰æ‹©æ€§èšåˆ prototypes ============
        old_prototypes = self.global_model.get_prototype_params()  # [num_classes, d]
        new_prototypes = old_prototypes.clone()
        
        # ç»Ÿè®¡æ¯ä¸ªç±»æœ‰å“ªäº›å®¢æˆ·ç«¯
        class_updates: Dict[int, List[torch.Tensor]] = {c: [] for c in range(self.num_classes)}
        
        for update in client_updates:
            local_classes = update['local_classes']
            client_protos = update['prototypes']  # [num_classes, d]
            
            for c in local_classes:
                class_updates[c].append(client_protos[c])
        
        # å¯¹æ¯ä¸ªç±»èšåˆåŸå‹
        aggregation_info = {}
        for c in range(self.num_classes):
            if len(class_updates[c]) == 0:
                continue
            
            # ç®€å•å¹³å‡
            stacked = torch.stack(class_updates[c], dim=0)  # [n, d]
            avg_proto = stacked.mean(dim=0)  # [d]
            
            # åŠ¨é‡æ›´æ–°
            new_prototypes[c] = self.momentum * old_prototypes[c] + (1 - self.momentum) * avg_proto
            
            self.class_client_count[c] = len(class_updates[c])
            aggregation_info[c] = len(class_updates[c])
        
        self.global_model.set_prototype_params(new_prototypes)
        
        if verbose:
            self._print_aggregation_info(num_clients, aggregation_info)
    
    def _aggregate_params(
        self,
        client_params_list: List[Dict[str, torch.Tensor]],
        old_params: Dict[str, torch.Tensor]
    ) -> Dict[str, torch.Tensor]:
        """
        èšåˆå‚æ•°ï¼ˆFedAvg + åŠ¨é‡ï¼‰
        
        Args:
            client_params_list: å®¢æˆ·ç«¯å‚æ•°åˆ—è¡¨
            old_params: æ—§çš„å…¨å±€å‚æ•°
        
        Returns:
            èšåˆåçš„å‚æ•°
        """
        num_clients = len(client_params_list)
        
        # FedAvg
        aggregated = {}
        for key in old_params.keys():
            stacked = torch.stack([p[key] for p in client_params_list], dim=0)
            aggregated[key] = stacked.mean(dim=0)
        
        # åŠ¨é‡æ›´æ–°
        new_params = {}
        for key in old_params.keys():
            new_params[key] = self.momentum * old_params[key] + (1 - self.momentum) * aggregated[key]
        
        return new_params
    
    def _print_aggregation_info(self, num_clients: int, aggregation_info: Dict[int, int]):
        """æ‰“å°èšåˆä¿¡æ¯"""
        print(f"\n         ğŸ“Š Aggregation Summary:")
        print(f"         â”œâ”€ Total clients: {num_clients}")
        print(f"         â”œâ”€ Prototype aggregation (selective):")
        for c, count in sorted(aggregation_info.items()):
            if count > 0:
                print(f"         â”‚  Class {c} ({self.class_names[c]:10s}): {count} clients")
        print(f"         â””â”€ Momentum: {self.momentum}")
    
    def finish_task(self, task_classes: List[int]):
        """å®Œæˆä»»åŠ¡ï¼Œæ›´æ–°å·²å­¦ä¹ ç±»åˆ«"""
        for cls in task_classes:
            if cls not in self.learned_classes:
                self.learned_classes.append(cls)
    
    def evaluate(
        self,
        test_loader: DataLoader,
        classes_to_eval: Optional[List[int]] = None
    ) -> Dict[str, float]:
        """
        è¯„ä¼°å…¨å±€æ¨¡å‹
        
        Args:
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            classes_to_eval: è¦è¯„ä¼°çš„ç±»åˆ«
        
        Returns:
            metrics: è¯„ä¼°æŒ‡æ ‡
        """
        self.backbone.eval()
        self.global_model.eval()
        
        total_correct_common = 0
        total_correct_full = 0
        total_samples = 0
        
        class_correct_common = {}
        class_correct_full = {}
        class_total = {}
        
        with torch.no_grad():
            for images, labels in test_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                # æå–ç‰¹å¾
                features = self.backbone(images)
                
                # å‰å‘ä¼ æ’­
                output = self.global_model(features)
                
                # é¢„æµ‹
                pred_common = torch.argmax(output['logits_common'], dim=-1)
                pred_full = torch.argmax(output['logits_full'], dim=-1)
                
                # ç»Ÿè®¡
                for i in range(len(labels)):
                    label = labels[i].item()
                    
                    if classes_to_eval and label not in classes_to_eval:
                        continue
                    
                    if label not in class_total:
                        class_total[label] = 0
                        class_correct_common[label] = 0
                        class_correct_full[label] = 0
                    
                    class_total[label] += 1
                    total_samples += 1
                    
                    if pred_common[i].item() == label:
                        class_correct_common[label] += 1
                        total_correct_common += 1
                    
                    if pred_full[i].item() == label:
                        class_correct_full[label] += 1
                        total_correct_full += 1
        
        metrics = {
            'accuracy_common': total_correct_common / max(total_samples, 1) * 100,
            'accuracy_full': total_correct_full / max(total_samples, 1) * 100,
            'total_samples': total_samples
        }
        
        # æ¯ç±»å‡†ç¡®ç‡
        for cls in class_total:
            metrics[f'class_{cls}_acc_common'] = (
                class_correct_common[cls] / class_total[cls] * 100
                if class_total[cls] > 0 else 0
            )
            metrics[f'class_{cls}_acc_full'] = (
                class_correct_full[cls] / class_total[cls] * 100
                if class_total[cls] > 0 else 0
            )
        
        return metrics
    
    def diagnose(self, test_loader: DataLoader) -> Dict:
        """
        è¯Šæ–­æ¨¡å‹æ€§èƒ½
        """
        self.backbone.eval()
        self.global_model.eval()
        
        # æ··æ·†çŸ©é˜µ
        confusion_common = torch.zeros(self.num_classes, self.num_classes)
        confusion_full = torch.zeros(self.num_classes, self.num_classes)
        
        with torch.no_grad():
            for images, labels in test_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                features = self.backbone(images)
                output = self.global_model(features)
                
                pred_common = torch.argmax(output['logits_common'], dim=-1)
                pred_full = torch.argmax(output['logits_full'], dim=-1)
                
                for i in range(len(labels)):
                    true_cls = labels[i].item()
                    confusion_common[true_cls, pred_common[i].item()] += 1
                    confusion_full[true_cls, pred_full[i].item()] += 1
        
        return {
            'confusion_common': confusion_common,
            'confusion_full': confusion_full,
            'class_names': self.class_names
        }
    
    def get_global_model_state(self) -> Dict:
        """è·å–å…¨å±€æ¨¡å‹çŠ¶æ€"""
        return {
            'model_state': self.global_model.state_dict(),
            'learned_classes': self.learned_classes.copy()
        }
    
    def load_global_model_state(self, state: Dict):
        """åŠ è½½å…¨å±€æ¨¡å‹çŠ¶æ€"""
        self.global_model.load_state_dict(state['model_state'])
        self.learned_classes = state['learned_classes']


if __name__ == "__main__":
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
                   'dog', 'frog', 'horse', 'ship', 'truck']
    
    model_config = {
        'backbone': 'resnet18',
        'backbone_pretrained': True,
        'feature_dim': 512,
        'hidden_dim': 256,
        'output_dim': 128,
        'num_layers': 3,
        'dropout': 0.1
    }
    
    server = FedPCIServer(
        num_classes=10,
        class_names=class_names,
        model_config=model_config,
        device=device,
        momentum=0.9
    )
    
    print(f"Server created on {device}")
    print(f"Number of classes: {server.num_classes}")
    
    # ç»Ÿè®¡å‚æ•°é‡
    total_params = sum(p.numel() for p in server.global_model.parameters())
    print(f"Total model parameters: {total_params:,}")
    
    # æµ‹è¯•è·å–å…¨å±€å‚æ•°
    global_params = server.get_global_params()
    print(f"\nGlobal params keys: {list(global_params.keys())}")
    print(f"g_common: {len(global_params['g_common'])} tensors")
    print(f"classifier_common: {list(global_params['classifier_common'].keys())}")
    print(f"prototypes shape: {global_params['prototypes'].shape}")
    
    # æ¨¡æ‹Ÿèšåˆ
    print("\n--- æ¨¡æ‹Ÿèšåˆæµ‹è¯• ---")
    
    # æ¨¡æ‹Ÿ3ä¸ªå®¢æˆ·ç«¯çš„æ›´æ–°
    client_updates = []
    for i in range(3):
        local_classes = [i, i+1, i+2]  # æ¯ä¸ªå®¢æˆ·ç«¯3ä¸ªç±»
        update = {
            'g_common': {k: v + torch.randn_like(v) * 0.1 for k, v in global_params['g_common'].items()},
            'classifier_common': {k: v + torch.randn_like(v) * 0.1 for k, v in global_params['classifier_common'].items()},
            'prototypes': global_params['prototypes'] + torch.randn_like(global_params['prototypes']) * 0.1,
            'local_classes': local_classes
        }
        client_updates.append(update)
    
    server.aggregate(client_updates, verbose=True)
    print("\nAggregation completed!")