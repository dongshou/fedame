"""
è”é‚¦å­¦ä¹ æœåŠ¡ç«¯æ¨¡å—ï¼ˆè§£è€¦è·¯ç”±å™¨ç‰ˆæœ¬ï¼‰
ç®¡ç†Nä¸ªç‹¬ç«‹Routerçš„èšåˆ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple
import copy

from models import (
    create_backbone,
    DecoupledRouterPool,
    ExpertPool
)
from anchor import create_anchor_generator, LLMDecisionMaker, ExpertManager


class DecoupledServer:
    """
    ä½¿ç”¨è§£è€¦è·¯ç”±å™¨çš„è”é‚¦æœåŠ¡ç«¯
    
    æ ¸å¿ƒç‰¹ç‚¹ï¼š
    - ç®¡ç†Nä¸ªç‹¬ç«‹çš„Routerï¼Œåˆ†åˆ«èšåˆ
    - ç®¡ç†å…¨å±€è§†è§‰åŸå‹
    - æŒ‰æ­£è´Ÿæ ·æœ¬æ•°é‡åŠ æƒèšåˆ
    """
    
    def __init__(
        self,
        num_classes: int,
        class_names: List[str],
        cluster_config: Dict[str, List[str]],
        model_config: Dict,
        device: str = "cuda",
        use_clip: bool = False,
        use_real_llm: bool = False
    ):
        self.num_classes = num_classes
        self.class_names = class_names
        self.cluster_config = cluster_config
        self.cluster_names = list(cluster_config.keys())
        self.device = device
        
        # åˆå§‹åŒ–é”šç‚¹ç”Ÿæˆå™¨
        self.anchor_generator = create_anchor_generator(
            use_clip=use_clip,
            device=device
        )
        
        # ç”ŸæˆCLIPè¯­ä¹‰é”šç‚¹
        self._generate_anchors()
        
        # åˆå§‹åŒ–å…¨å±€æ¨¡å‹ç»„ä»¶
        self._init_global_model(model_config)
        
        # åˆå§‹åŒ–LLMå†³ç­–å™¨å’Œä¸“å®¶ç®¡ç†å™¨
        self.llm_decision_maker = LLMDecisionMaker(use_real_llm=use_real_llm)
        self.expert_manager = ExpertManager(
            self.llm_decision_maker,
            class_names,
            self.cluster_names
        )
        self.expert_manager.initialize_experts(cluster_config)
        
        # åŒæ­¥ä¸“å®¶æ± çš„ç±»åˆ«åˆ†é…
        self._sync_expert_assignments()
        
        # æ³¨æ„ï¼šglobal_visual_prototypes å’Œ global_prototype_counts 
        # å·²åœ¨ _init_global_model ä¸­åˆå§‹åŒ–ï¼Œä¸è¦åœ¨è¿™é‡Œè¦†ç›–
        
        # å·²å­¦ä¹ çš„ç±»åˆ«
        self.learned_classes: List[int] = []
        
        # å®¢æˆ·ç«¯ä¿¡æ¯
        self.client_info: Dict[int, Dict] = {}
    
    def _generate_anchors(self):
        """ç”Ÿæˆå…¨å±€CLIPè¯­ä¹‰é”šç‚¹"""
        # ç”Ÿæˆç±»é”šç‚¹
        self.class_anchors = self.anchor_generator.generate_anchors(
            self.class_names
        ).to(self.device)
        
        # ç”Ÿæˆç°‡é”šç‚¹
        self.cluster_anchors = self.anchor_generator.generate_anchors(
            self.cluster_names
        ).to(self.device)
        
        print(f"   ğŸ“ Generated {len(self.class_anchors)} class anchors")
    
    def _init_global_model(self, config: Dict):
        """åˆå§‹åŒ–å…¨å±€æ¨¡å‹"""
        # Backboneï¼ˆå†»ç»“ï¼‰
        self.backbone = create_backbone(
            backbone_type=config.get('backbone', 'resnet18'),
            pretrained=config.get('backbone_pretrained', True),
            frozen=True
        ).to(self.device)
        
        # è§£è€¦è·¯ç”±å™¨æ± ï¼ˆNä¸ªç‹¬ç«‹çš„Routerï¼‰
        self.global_router_pool = DecoupledRouterPool(
            num_classes=self.num_classes,
            input_dim=config.get('feature_dim', 512),
            hidden_dim=config.get('router_hidden_dim', 256),
            output_dim=config.get('anchor_dim', 512),
            num_layers=config.get('router_num_layers', 3),
            dropout=config.get('router_dropout', 0.1)
        ).to(self.device)
        
        # è®¾ç½®CLIPé”šç‚¹
        self.global_router_pool.set_class_anchors(self.class_anchors)
        
        # ä¸“å®¶æ± 
        self.global_expert_pool = ExpertPool(
            input_dim=config.get('anchor_dim', 512),
            hidden_dim=config.get('expert_hidden_dim', 256),
            output_dim=config.get('expert_output_dim', 512),
            num_initial_experts=self.num_classes
        ).to(self.device)
        
        # åˆå§‹åŒ–å…¨å±€è§†è§‰åŸå‹ä¸ºé›¶
        self.global_visual_prototypes = torch.zeros(
            self.num_classes, 
            config.get('feature_dim', 512),
            device=self.device
        )
        self.global_prototype_counts: Dict[int, int] = {}
    
    def _sync_expert_assignments(self):
        """åŒæ­¥ä¸“å®¶åˆ†é…åˆ°ä¸“å®¶æ± """
        for exp_id, info in self.expert_manager.expert_info.items():
            for cls in info['responsible_classes']:
                self.global_expert_pool.assign_class_to_expert(cls, exp_id)
    
    def prepare_task(self, task_classes: List[int]) -> Dict:
        """
        å‡†å¤‡æ–°ä»»åŠ¡
        
        Args:
            task_classes: ä»»åŠ¡åŒ…å«çš„ç±»åˆ«ID
        
        Returns:
            task_info: ä»»åŠ¡ä¿¡æ¯
        """
        new_classes = [c for c in task_classes if c not in self.learned_classes]
        
        # ä¸ºæ–°ç±»åˆ†é…ä¸“å®¶
        for cls in new_classes:
            class_name = self.class_names[cls]
            expert_id, cluster = self.expert_manager.assign_new_class(
                class_name,
                self.class_anchors,
                self.cluster_anchors
            )
            self.global_expert_pool.assign_class_to_expert(cls, expert_id)
        
        # æ„å»ºä»»åŠ¡ä¿¡æ¯
        task_info = {
            'task_classes': task_classes,
            'new_classes': new_classes,
            'old_classes': self.learned_classes.copy(),
            'expert_assignments': self.global_expert_pool.class_to_expert.copy(),
            'expert_info': self.global_expert_pool.get_expert_info()
        }
        
        return task_info
    
    def get_client_config(
        self,
        client_id: int,
        client_classes: List[int]
    ) -> Dict:
        """
        è·å–å®¢æˆ·ç«¯é…ç½®
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            client_classes: å®¢æˆ·ç«¯æ‹¥æœ‰çš„ç±»åˆ«
        
        Returns:
            config: å®¢æˆ·ç«¯é…ç½®
        """
        # ç¡®å®šå®¢æˆ·ç«¯éœ€è¦çš„ä¸“å®¶
        needed_experts = set()
        for cls in client_classes:
            exp_id = self.global_expert_pool.get_expert_for_class(cls)
            needed_experts.add(exp_id)
        
        # ä¿å­˜å®¢æˆ·ç«¯ä¿¡æ¯
        self.client_info[client_id] = {
            'classes': client_classes,
            'experts': list(needed_experts)
        }
        
        # è·å–æ‰€æœ‰Routerçš„å‚æ•°
        router_params = {}
        for i in range(self.num_classes):
            router_params[i] = self.global_router_pool.get_router_params(i)
        
        # è·å–ç›¸å…³ä¸“å®¶çš„å‚æ•°
        expert_states = {}
        for exp_id in needed_experts:
            expert = self.global_expert_pool.get_expert(exp_id)
            expert_states[exp_id] = expert.state_dict()
        
        # è·å–å…¨å±€è§†è§‰åŸå‹
        prototype_info = {
            'prototypes': self.global_visual_prototypes.cpu(),
            'counts': self.global_prototype_counts.copy()
        }
        
        return {
            'client_id': client_id,
            'local_classes': client_classes,
            'local_experts': list(needed_experts),
            'class_to_expert': self.global_expert_pool.class_to_expert.copy(),
            'router_params': router_params,
            'expert_states': expert_states,
            'prototype_info': prototype_info,
            'class_anchors': self.class_anchors.cpu()
        }
    
    def aggregate(
        self,
        client_router_updates: Dict[int, Dict[int, Dict[str, torch.Tensor]]],
        client_prototype_updates: Dict[int, Dict[int, Dict]],
        client_train_stats: Dict[int, Dict[int, Dict]]
    ):
        """
        èšåˆå®¢æˆ·ç«¯æ›´æ–°
        
        Args:
            client_router_updates: {client_id: {class_id: {param_name: param_value}}}
            client_prototype_updates: {client_id: {class_id: {'prototype': tensor, 'count': int}}}
            client_train_stats: {client_id: {class_id: {'pos_count': int, 'neg_count': int}}}
        """
        # 1. èšåˆæ¯ä¸ªRouterï¼ˆæŒ‰æ­£è´Ÿæ ·æœ¬æ•°é‡åŠ æƒï¼‰
        self._aggregate_routers(client_router_updates, client_train_stats)
        
        # 2. èšåˆè§†è§‰åŸå‹
        self._aggregate_prototypes(client_prototype_updates)
        
        # 3. èšåˆä¸“å®¶ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
        # è¿™é‡Œæš‚æ—¶ä¸èšåˆä¸“å®¶ï¼Œå› ä¸ºä¸“å®¶æ˜¯æŒ‰ç±»åˆ«åˆ†é…çš„
    
    def _aggregate_routers(
        self,
        client_router_updates: Dict[int, Dict[int, Dict[str, torch.Tensor]]],
        client_train_stats: Dict[int, Dict[int, Dict]]
    ):
        """
        èšåˆæ‰€æœ‰Router
        
        å¯¹äºæ¯ä¸ªRouter_iï¼š
        - æ”¶é›†æ‰€æœ‰å®¢æˆ·ç«¯çš„Router_iå‚æ•°
        - æŒ‰ Î±*æ­£æ ·æœ¬æ•° + Î²*è´Ÿæ ·æœ¬æ•° åŠ æƒ
        - Î± > Î²ï¼Œç»™æ­£æ ·æœ¬æ›´é«˜æƒé‡
        """
        if len(client_router_updates) == 0:
            return
        
        alpha = 2.0  # æ­£æ ·æœ¬æƒé‡
        beta = 1.0   # è´Ÿæ ·æœ¬æƒé‡
        
        # å¯¹æ¯ä¸ªç±»çš„Routeråˆ†åˆ«èšåˆ
        for class_id in range(self.num_classes):
            # æ”¶é›†è¯¥ç±»Routerçš„æ‰€æœ‰æ›´æ–°
            class_updates = []
            class_weights = []
            
            for client_id, router_updates in client_router_updates.items():
                if class_id in router_updates:
                    params = router_updates[class_id]
                    
                    # è·å–è¯¥å®¢æˆ·ç«¯å¯¹è¯¥ç±»çš„è®­ç»ƒç»Ÿè®¡
                    stats = client_train_stats.get(client_id, {}).get(class_id, {})
                    pos_count = stats.get('pos_count', 0)
                    neg_count = stats.get('neg_count', 0)
                    
                    # è®¡ç®—æƒé‡
                    weight = alpha * pos_count + beta * neg_count
                    
                    # åªæœ‰æœ‰è®­ç»ƒæ•°æ®çš„æ‰å‚ä¸èšåˆ
                    if weight > 0:
                        class_updates.append(params)
                        class_weights.append(weight)
            
            # å¦‚æœæœ‰æ›´æ–°ï¼Œè¿›è¡ŒåŠ æƒèšåˆ
            if len(class_updates) > 0:
                total_weight = sum(class_weights)
                normalized_weights = [w / total_weight for w in class_weights]
                
                # èšåˆå‚æ•°
                aggregated_params = {}
                for param_name in class_updates[0].keys():
                    aggregated_params[param_name] = sum(
                        w * upd[param_name].to(self.device)
                        for w, upd in zip(normalized_weights, class_updates)
                    )
                
                # æ›´æ–°å…¨å±€Router
                self.global_router_pool.set_router_params(class_id, aggregated_params)
    
    def _aggregate_prototypes(
        self,
        client_prototype_updates: Dict[int, Dict[int, Dict]]
    ):
        """
        èšåˆè§†è§‰åŸå‹
        
        æŒ‰æ ·æœ¬æ•°é‡åŠ æƒå¹³å‡
        """
        if len(client_prototype_updates) == 0:
            return
        
        # å¯¹æ¯ä¸ªç±»åˆ†åˆ«èšåˆ
        for class_id in range(self.num_classes):
            prototypes = []
            counts = []
            
            for client_id, proto_updates in client_prototype_updates.items():
                if class_id in proto_updates:
                    proto_info = proto_updates[class_id]
                    prototypes.append(proto_info['prototype'])
                    counts.append(proto_info['count'])
            
            # å¦‚æœæœ‰åŸå‹æ›´æ–°
            if len(prototypes) > 0:
                total_count = sum(counts)
                if total_count > 0:
                    # åŠ æƒå¹³å‡
                    weights = [c / total_count for c in counts]
                    aggregated_proto = sum(
                        w * p.to(self.device)
                        for w, p in zip(weights, prototypes)
                    )
                    
                    self.global_visual_prototypes[class_id] = aggregated_proto
                    self.global_prototype_counts[class_id] = total_count
    
    def finish_task(self, task_classes: List[int]):
        """å®Œæˆä»»åŠ¡ï¼Œæ›´æ–°å·²å­¦ä¹ ç±»åˆ«"""
        for cls in task_classes:
            if cls not in self.learned_classes:
                self.learned_classes.append(cls)
    
    def evaluate(
        self,
        test_loader: DataLoader,
        classes_to_eval: Optional[List[int]] = None
    ) -> Dict[str, float]:
        """
        è¯„ä¼°å…¨å±€æ¨¡å‹
        
        Args:
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            classes_to_eval: è¦è¯„ä¼°çš„ç±»åˆ«
        
        Returns:
            metrics: è¯„ä¼°æŒ‡æ ‡
        """
        self.backbone.eval()
        self.global_router_pool.eval()
        self.global_expert_pool.eval()
        
        total_correct = 0
        total_samples = 0
        routing_correct = 0
        
        class_correct = {}
        class_total = {}
        class_routing_correct = {}
        
        with torch.no_grad():
            for images, labels in test_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                # æå–ç‰¹å¾
                features = self.backbone(images)
                
                # è·¯ç”±å†³ç­–
                routed_classes, distances, similarities = self.global_router_pool(features)
                
                # ç›®æ ‡ä¸“å®¶
                target_experts = torch.tensor(
                    [self.global_expert_pool.get_expert_for_class(l.item()) for l in labels],
                    device=self.device
                )
                
                # è·¯ç”±å‡†ç¡®ç‡
                routing_match = (routed_classes == labels)
                routing_correct += routing_match.sum().item()
                
                # ä½¿ç”¨è·¯ç”±çš„ä¸“å®¶è¿›è¡Œåˆ†ç±»
                cls_logits, _ = self.global_expert_pool(
                    features, routed_classes, self.class_anchors
                )
                _, predicted = cls_logits.max(1)
                
                # ç»Ÿè®¡
                for i in range(len(labels)):
                    label = labels[i].item()
                    
                    if classes_to_eval and label not in classes_to_eval:
                        continue
                    
                    if label not in class_total:
                        class_total[label] = 0
                        class_correct[label] = 0
                        class_routing_correct[label] = 0
                    
                    class_total[label] += 1
                    total_samples += 1
                    
                    if predicted[i].item() == label:
                        class_correct[label] += 1
                        total_correct += 1
                    
                    if routing_match[i].item():
                        class_routing_correct[label] += 1
        
        metrics = {
            'accuracy': total_correct / max(total_samples, 1) * 100,
            'routing_accuracy': routing_correct / max(total_samples, 1) * 100,
            'total_samples': total_samples
        }
        
        for cls in class_total:
            metrics[f'class_{cls}_acc'] = (
                class_correct[cls] / class_total[cls] * 100
                if class_total[cls] > 0 else 0
            )
            metrics[f'class_{cls}_routing_acc'] = (
                class_routing_correct[cls] / class_total[cls] * 100
                if class_total.get(cls, 0) > 0 else 0
            )
        
        return metrics
    
    def diagnose_routing(
        self,
        test_loader: DataLoader,
        class_names: Optional[List[str]] = None
    ) -> Dict:
        """
        è¯Šæ–­è·¯ç”±æƒ…å†µ
        
        Args:
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
        
        Returns:
            diagnosis: è·¯ç”±è¯Šæ–­ç»“æœ
        """
        self.backbone.eval()
        self.global_router_pool.eval()
        
        if class_names is None:
            class_names = [f"class_{i}" for i in range(self.num_classes)]
        
        # ç»Ÿè®¡æ¯ä¸ªç±»è¢«è·¯ç”±åˆ°å“ªäº›ç±»
        class_routing_stats = {}  # {true_class: {routed_class: count}}
        class_total_samples = {}
        
        with torch.no_grad():
            for images, labels in test_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                features = self.backbone(images)
                routed_classes, _, _ = self.global_router_pool(features)
                
                for i in range(len(labels)):
                    true_cls = labels[i].item()
                    routed_cls = routed_classes[i].item()
                    
                    if true_cls not in class_routing_stats:
                        class_routing_stats[true_cls] = {}
                        class_total_samples[true_cls] = 0
                    
                    if routed_cls not in class_routing_stats[true_cls]:
                        class_routing_stats[true_cls][routed_cls] = 0
                    
                    class_routing_stats[true_cls][routed_cls] += 1
                    class_total_samples[true_cls] += 1
        
        # è®¡ç®—è·¯ç”±å‡†ç¡®ç‡
        class_routing_accuracy = {}
        total_correct = 0
        total_samples = 0
        
        for cls in class_routing_stats:
            correct = class_routing_stats[cls].get(cls, 0)
            total = class_total_samples[cls]
            class_routing_accuracy[cls] = correct / total if total > 0 else 0
            total_correct += correct
            total_samples += total
        
        return {
            'class_routing_stats': class_routing_stats,
            'class_total_samples': class_total_samples,
            'class_routing_accuracy': class_routing_accuracy,
            'overall_accuracy': total_correct / total_samples if total_samples > 0 else 0,
            'total_correct': total_correct,
            'total_samples': total_samples,
            'class_names': class_names
        }
    
    def get_global_model_state(self) -> Dict:
        """è·å–å…¨å±€æ¨¡å‹çŠ¶æ€"""
        router_params = {}
        for i in range(self.num_classes):
            router_params[i] = self.global_router_pool.get_router_params(i)
        
        return {
            'router_params': router_params,
            'experts': {
                int(k): v.state_dict()
                for k, v in self.global_expert_pool.experts.items()
            },
            'visual_prototypes': self.global_visual_prototypes.cpu(),
            'prototype_counts': self.global_prototype_counts.copy(),
            'learned_classes': self.learned_classes.copy(),
            'expert_assignments': self.global_expert_pool.class_to_expert.copy()
        }
    
    def load_global_model_state(self, state: Dict):
        """åŠ è½½å…¨å±€æ¨¡å‹çŠ¶æ€"""
        # åŠ è½½Routerå‚æ•°
        for class_id, params in state['router_params'].items():
            self.global_router_pool.set_router_params(class_id, params)
        
        # åŠ è½½ä¸“å®¶å‚æ•°
        for exp_id, exp_state in state['experts'].items():
            self.global_expert_pool.get_expert(exp_id).load_state_dict(exp_state)
        
        # åŠ è½½è§†è§‰åŸå‹
        self.global_visual_prototypes = state['visual_prototypes'].to(self.device)
        self.global_prototype_counts = state['prototype_counts']
        
        # åŠ è½½å…¶ä»–ä¿¡æ¯
        self.learned_classes = state['learned_classes']


# æµ‹è¯•
if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    cluster_config = {
        'animals': ['cat', 'dog', 'bird', 'deer', 'frog', 'horse'],
        'vehicles': ['airplane', 'automobile', 'ship', 'truck']
    }
    
    model_config = {
        'backbone': 'resnet18',
        'backbone_pretrained': True,
        'feature_dim': 512,
        'router_hidden_dim': 256,
        'anchor_dim': 512,
        'router_num_layers': 3,
        'router_dropout': 0.1,
        'expert_hidden_dim': 256,
        'expert_output_dim': 512
    }
    
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
                   'dog', 'frog', 'horse', 'ship', 'truck']
    
    server = DecoupledServer(
        num_classes=10,
        class_names=class_names,
        cluster_config=cluster_config,
        model_config=model_config,
        device=device,
        use_clip=False,
        use_real_llm=False
    )
    
    print(f"Server created on {device}")
    print(f"Number of classes: {server.num_classes}")
    print(f"Router pool parameters: {sum(p.numel() for p in server.global_router_pool.parameters()):,}")